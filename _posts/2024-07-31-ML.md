---
layout: post
title:  "혼공 ML 2-2장"
published: true
date:   2024-07-31 02:50:00
categories: ML(MachineLearning)
---

# 2-2 데이터 전처리 

## 2-2-1 NUMPY로 데이터 준비하기

Numpy로 0과 1로 구성된 배열 만드는 방법

```python
import numpy as np

np.ones(N)

np.zeros(M)
```

Numpy에서 만들 수 있는 배열의 종류

1. np.coulmnn_stack(): 세로로 된 배열을 생성
2. np.concatenate(): 가로로 된 배열 생성

![image](https://github.com/user-attachments/assets/f041595f-576f-4b2c-9bf7-7261d074b932)


### 2-2-1-1 Numpy 배열

Numpy의 3차원 배열은 arr[z,y,x]로 이루어져 있음   
모든 인덱스는 0부터 시작

- 첫 번째 차원(z): 깊이(depth) 또는 페이지(page)
- 두 번째 차원(y): 행(row)
- 세 번째 차원(x): 열(column)
- [:]: 헤당 차원 전체 선택
- [:K]: 해당 차원 K-1번째까지 선택
- [K]: 해당 차원 K-1번째 선택
- []가 어디까지 지정되어 있는지 잘 구분할 것

train_input이 아래와 같다고 하자
```python
train_input = np.array([
    [[1, 2, 3], [4, 5, 6]],
    [[7, 8, 9], [10, 11, 12]],
    [[13, 14, 15], [16, 17, 18]]
])
```
이 배열의 형태는 (3,2,3)이다
```python
train_input.shape()
```

1. 첫번째 차원에 대한 슬라이싱
```python
#첫번째 차원 두페이지까지 선택

train_input[:2]
```
결과   

![image](https://github.com/user-attachments/assets/51c943dc-3073-4ca8-8eac-8786d0417248)

2. 두번째 차원에 대한 슬라이싱

```PYTHON
#각 페이지에서 첫번째 행 선택

train_input[:, :1]
```
결과   

![image](https://github.com/user-attachments/assets/7938212b-15a9-40af-b622-0309d635043b)

3. 세 번째 차원에 대한 슬라이싱

```PYTHON
#각 행에서 첫 두 열을 선택

train_input[:, :, :2]
```
결과
![image](https://github.com/user-attachments/assets/81a7d583-ae82-4aba-83a4-6a3e51556fce)


## 2-1-2 사이킷런으로 훈련세트와 테스트 세트 나누기

### train_test_split() 함수
- 리스트나 배열을 비율에 맞게 훈련 세트와 테스트 세트로 나누어 주는 함수

```python
from sklearn.model_selection import train_test_split
```

- 기본적으로 25%를 테스트 세트로 지정

```python
#random_stat: 시드 지정, 특정 시드를 입력하면 계속 같은 값이 나오게 만들 수 있다

#fish_data, fish_target을 받아서 랜덤으로 테스트 세트 제작

train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, random_state=42)
```

아래의 코드를 실행하면 (36,2), (13,2)가 출력된다


```python
#shape: 배열의 형태를 보여줌, 출력값은(z,y,x) 순으로 생각

print(train_input.shape, test_input.shape)
```

- train_test_split 함수를 사용해도 일부 클래스의 개수가 적으면 테스트 세트에서 샘플링 편향이 일어날 수 있음
>**stratify 매개변수**에 타깃 데이터를 전달하면 클래스 비율에 맞게 데이터를 나눌 수 있다

```python
train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target,stratify=fish_target,random_state=42) 
```
## 2-2-3 기준점 맞추기


```python
import matplotlib.pyplot as plt   

#kneighbors(): 주어진 샘플에서 가장 가까운 이웃을 찾아주는 메서드
#[25,150]과 가장 가까운 5점들의 거리와 인덱스를 반환
distances, indexes = kn.kneighbors([[25, 150]])

#train_input의 모든 행에서 첫 번째 열(길이)과 두 번째 열(무게)의 데이터를 사용하여 산점도를 그림
plt.scatter(train_input[:,0], train_input[:,1])

#marke:모양을 지정(^: 삼각형, D: 마름모)
plt.scatter(25, 150, marker='^') 

#[25,150]과 가장 가까운 데이터들의 인덱스를 지닌 데이터에서 각각 첫번째 열과 두번째 열을 선택

plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

위의 코드를 실행하면 아래와 같은 산점도가 나온다
![image](https://github.com/user-attachments/assets/638791c6-3310-48d8-a19c-31d9c5e4f9fd)

산점도에서 보이는 것처럼 [25,150]의 데이터는 도미(1)에 가까워 보이지만 

```PYTHON
kn.predict([[25, 150]])
```
위 코드를 실행하면 array([0.])을 반환한다. 

**Q. 왜 이런것일까?**

>A. 길이와 무게의 값이 놓인 범위, 즉 X축과 Y축이 놓인 범위가 다르기 때문이다.    
![image](https://github.com/user-attachments/assets/566b51ed-7edc-4948-9420-3ac7187d87b0)

> 92와 130 사이의 거리 차이가 크게 왜곡 되어 있다.   
이것을 **스케일이 다르다**고 말한다

데이터를 표현하는 기준이 다르면 알고리즘이 올바르게 예측할 수 없다.   

특히 거리 기반 알고리즘에서는 이 경향이 더 심해진다   

따라서 데이터 전처리가 필요하다.

### 2-3-3-1 표준 점수(Z 점수)
- 가장 널리 사용하는 전처리 방법 중 하나
- 각 특성앖이 0에서 표준편차의 몇배 만큼 떨어져 있는지를 나타냄
- 계산방법: 평균을 빼고 표준편차로 나누어 

```python
#axis=0 : 첫번째 차원을 축으로 하여 계산한다(여기서는 y축)
mean=np.mean(train_input, axis=0)
std=np.std(train_input, axis=0)

train_scaled = (train_input-mean)/std
```

하지만 이 결과를 가지고 바로 산점도를 그려도 원하는 결과가 나오지 않는다
![image](https://github.com/user-attachments/assets/4ba90f51-dea5-4919-bd1b-0a89cc1a61a6)

샘플[20,150]도 동일한 비율, 즉 훈련 세트의 mean과 std를 사용하여 변환 해야 한다.

```python
new=(25-mean)/std
plt.scatter(train_scaled[:,0], train_scaled[:,1])
plt.scatter(new[0], new[1], marker='^') 
plt.xlabel('length')
plt.ylabel('weight')
plt.show()  
```
![image](https://github.com/user-attachments/assets/10f6f453-2c1c-45c0-acd2-0f53024d4f8e)

마지막으로 테스트 세트의 스케일까지 변환을 완료 한 후 모델 검증을 실시한다. 
```python
test_scaled=(test_input-mean)/std
kn.fit(train_scaled, train_target)
kn.score(test_scaled, test_target)
```
그러면 실행결과로 1.0이 반환된다

```python
print(kn.predict([new]))
``` 
마지막으로 예측값도 [1.]이 반환된다

```python
distances, indexes = kn.kneighbors([new])
plt.scatter(train_scaled[:,0], train_scaled[:,1])
plt.scatter(new[0], new[1], marker='^')
plt.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker='D')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()  
```
 ![image](https://github.com/user-attachments/assets/b9de3f01-189f-4f06-9a08-eb22d858daf4)

위 코드로 새롭게 그래년 k-최근접 이웃도 전부 도미로 새롭게 표시 된 것을 알 수 있다.