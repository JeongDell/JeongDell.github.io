---
layout: post
title:  "혼공 ML 6-2장"
published: true
date:   2024-08-26 03:50:00
categories: ML(MachineLearning)
permalink: /ml/6-2
---

# 6-2 k- 평균

## k-평균 알고리즘

1. 무작위로 k개의 클러스터 중심을 정함
2. 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스트의 샘플로 지정
3. 클러스터에 속한 샘플의 평균값으로 클러스터 중심을 변경
4. 클러스터 중심에 변화가 없을 때까지 2번으로 돌아가 반복

![image](https://github.com/user-attachments/assets/0ca5ad34-5a96-4d0f-8573-5eda69ceb67a)

## KMeans 클래스

``` python
# 2차원 배열로 변경
import numpy as np
mnist_2d= mnist[:, 1:].reshape(-1,28*28)

if np.isnan(mnist_2d).any():
    print("Dataset contains NaN values.")

# 데이터셋에 nan 있으면 제거
# n_clsuter: 사용할 클러스터(군집의 개수) 지정
from sklearn.cluster import KMeans
km = KMeans(n_clusters=10, random_state=42)
mnist_2d_cleaned = mnist_2d[~np.isnan(mnist_2d).any(axis=1)]
km.fit(mnist_2d_cleaned)

# 각 클러스터 별로 1행에 10개의 데이터가 들어가도록 draw_mnist 지정
import matplotlib.pyplot as plt
def draw_mnist(arr, ratio=1):
    #n: 샘플 개수
    n = len(arr)
    #한 줄에 10개의 이미지를 그림, 샘플 개수를 10으로 나누어 전체 행 개수 계싼
    rows = int(np.ceil(n / 10))
    #행이 1개이면 열의 개수는 샘플 개수, 그렇지 않으면 기본값은 10ㄱ0
    cols = n if rows < 2 else 10
    fig, axes = plt.subplots(rows, cols, figsize=(2 * cols * ratio, 2 * rows * ratio), squeeze=False)
    for i in range(rows):
        for j in range(cols):
            if i * 10 + j < n:
                axes[i, j].imshow(arr[i * 10 + j].reshape(28, 28), cmap='gray')
            else:
                axes[i, j].axis('off')
    plt.show()

draw_mnist(mnist_2d_cleaned[km.labels_ == 0])
```

### 불리언 인덱싱

```python
# km.labels ==4 인 데이터만 출력
draw_mnist(mnist_2d_cleaned[km.labels_ == 4])
```

![image](https://github.com/user-attachments/assets/5d9c7417-79c8-4187-838b-e0b4367d41fe)

## 클러스터 중심

- kMeans가 찾은 클러스터 중심은 cluster_centers_ 속성에 저장되어 있음

```pyhton
draw_mnist(km.cluster_centers_.reshape(-1,28,28), ratio =10)
```

![image](https://github.com/user-attachments/assets/5a72fb58-c1c8-4ecb-be6b-554f6dfa0494)

## 최적의 k 찾기

### 엘보우
- 이너서: k-평균 알고리즘은 클러스터 중심과 클러스터에 속한 샘플 사이의 거리를 잴 수 잇음
   - 이 거리의 제곱합이 이너셔
   - 이너셔는 클러스터에 속한 샘플이 얼마나 가깝게 모여있는지를 나타내는 값으로 생각할 수 있음
   - 일반적으로 클러스터의 개수가 늘어나면 이너셔는 줄어듦
- 엘보우 방법은 클러스터 개수를 늘려가면서 이너셔의 변화를 관찰하여 최적의 클러스터 개수를 찾는 방법  

![image](https://github.com/user-attachments/assets/57fea8bc-7433-4783-8fd5-0d2bd536b44e)

``` python
inerita= []
for k in range(11,20):
  km = KMeans(n_clusters=k, random_state=42)
  km.fit(mnist_2d_cleaned)
  inerita.append(km.inertia_)
plt.plot(range(11,20), inerita, marker='o')
plt.xlabel('Number of clusters (k)')
plt.ylabel('Inertia')
plt.show()
```

![image](https://github.com/user-attachments/assets/97d41ce0-8905-4e51-9cf3-76ad20639c54)