---
layout: post
title:  "혼공 ML 5-2장"
published: true
date:   2024-08-19 03:50:00
categories: ML(MachineLearning)
permalink: /ml/5-2
---

# 5-2 교차 검증과 그리드 서치

## 검증세트

- 테스트 세트로 일반화 성능을 올바르게 예측하려면 가능한 테스트 세트를 사용하지 않아야 한다.
- 테스트 세트를 사용하지 않으면 모델이 과대적합인지, 과소적합인지 판단하기 어렵다
- 따라서 훈련세트를 또 다시 나누어서 검증 세트로 활용한다

- 다음과 같은 순서로 모델 훈련이 이루어딘다
  1. 훈련세트에서 모델을 훈련하고 검증 세트로 모델을 평가한다
  2. 테스트 하고 싶은 매개변수를 바꿔가며 가장 좋은 모델을 고른다
  3. 결정한 매개변수를 사용해 훈련세트와 검증 세트를 합쳐서 전체 훈련 데이터에서 모델을 다시 훈련한다
  4. 테스트 세트에서 최종점수를 평가한다

```python

#train_input, train_targert을 다시 나눠서 검증세트 만들기

  sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)
  ```

  ## 교차검증

  - 교차검증을 실시하여 안정적인 검증 점수를 얻고, 훈련에 더 많은 데이터를 사용할 수 있다

- 아래 그림은 30폴드 교차 검증이 어떻게 이뤄지는지 나타낸 그림이다
  ![image](https://github.com/user-attachments/assets/2c5ad402-24a4-45f7-8945-718122f2df13)

- 5-폴드 교차 검증, 10-폴드 교차 검증을 사용하여 데이터의 80~90%까지 훈련에 사용할 수 있다
- 사이킷런에서는 cross_validate()라는 교차 검증 함수가 존재함

  - 사용방법은 평가할 모델 객체를 첫번째 매개변수로 전달하고, 훈련세트 전체를 croos_validate()함수에 전달함

``` python

# dt: 의사결정트리모델
from sklearn.model_selection import cross_validate
scores = cross_validate(dt, train_input, train_target)
print(scores)

{'fit_time': array([0.01964974, 0.01925254, 0.04155374, 0.03319049, 0.02357769]), 'score_time': array([0.00217271, 0.00228763, 0.00207901, 0.00225997, 0.00210047]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}

```
- fit_time: 모델을 훈련하는 시간
- score_time: 모델을 검증하는 시간
- test_score: 검증 폴더의 점수

따라서 검증폴더의 점수를 평균내면 교차검증의 점수를 구할 수 있다

```python
import numpy as np
print(np.mean(scores['test_score']))

0.855300214703487
```

- cross_validate()는 훈련세트를 섞어서 폴드를 나누지 않기 때문에 train_test_split() 함수를 미리 사용하거나 분할기를 지정해야 한다
- cross_validate() 함수는 기본적으로 회귀 모델인 경우 KFold 분할기를, 분류 모델일 경우 StratifiedFold를 사용한다

즉 앞서 진행한 교차 검증의 코드는 아래와 동일하다

``` python
from sklearn.model_selection import StratifiedKFold
scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))

# 훈련세트를 섞은 후 10-폴드 교차 검증을 수행하려면 아래와 같이 n_splits 매개변수를 수정한다
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
```

## 하이퍼파라미터 튜닝

- 하이퍼 파라미터: 모델이 학습할 수 없어서 사용자가 직접 지정해야만 하는 파라미터

- 결정 트리 모델에서는 max_depth, min_samples_split 값이 해당한다
- 매개변수가 많아지면 매개변수간 최적의 값을 찾는 과정이 복자배진다

- 따라서 사이킷런의 그리그 서치를 사용한다
  - 사이킷런의 GridSearch  클래스는 하이퍼파리미터 탐색과 교차검증을 한번에 수행한다

``` python
#그리드 서치 import
from sklearn.model_selection import GridSearchCV

#탐색할 매개변수 지정
#불순도 감소 최소량, 최대 깊이, 노드를 나누가 위한 최소 샘플 수 순
#넘파이 arrange: 0.0001에서 시작해서 0.001에 도달할 때까지 0.0001 더하는 배열 생성, 두번째 매개변수는 제외
#range(): 정수만 사용 가능, 5부터 20까지 1씩 증가흐는 배열
params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001), 'max_depth': range(5, 20, 1), 'min_samples_split': range(2, 100, 10)}  

#n_jobs: 사용할 코어수 지정, -1은 전체 코어
#params에 탐색할 매개변수 전달
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)

#그리드 서치는 훈련이 끝나면 검증 점수가 가장 높은 모델의 매개변수 조합으로 전체 훈련세트에서 자동으로 다시 모델을 훈련함
gs.fit(train_input, train_target)

# 최종 모델은 best_estimator_ 속성에 저장되어 있음
dt = gs.best_estimator_
print(dt.score(train_input, train_target)) 

0.892053107562055

#각 최적의 파라미터는 best_params에 저장되어 있음
print(gs.best_params_ )
{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}

#교차 검증으로 얻은 점수 출력
print(gs.cv_results_['mean_test_score'])

# 최상의 교차 검증 점수 확인
print(np.max(gs.cv_results_['mean_test_score']))
0.8683865773302731
```
## 랜덤서치

- 매개변수의 값이 수치일 때 값의 범위나 간격을 미리 정하기 어려울 수 있음
- 또한 너뭄 낳은 매개변수 조건이 있어 그리드 서치 수행시간이 오래 걸릴 수 있음
- 이때 랜덤 서치를 사용
- 랜덤 서치에는 매개변수를 샘플링할 수 있는 확률 분포 객체를 전달함

```python
#scipy: 파이썬의 과학 라이브러리 중 하나
#uniform: 실숫값을 주어진 범위에서 고르게 뽑음
#randint: 정수값을 주어진 범위에서 고르게 뽑음
from scipy.stats import uniform, randint

params = {'min_impurity_decrease': uniform(0.0001, 0.001), 'max_depth': randint(20,50), 'min_samples_split': randint(2,25), 'min_samples_leaf': randint(1,25)}
from sklearn.model_selection import RandomizedSearchCV
gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter=100, n_jobs=-1, random_state=42)
gs.fit(train_input, train_target)

print(gs.best_params_)
{'max_depth': 39, 'min_impurity_decrease': 0.00034102546602601173, 'min_samples_leaf': 7, 'min_samples_split': 13}

print(np.max(gs.cv_results_['mean_test_score']))  
0.8695428296438884

dt = gs.best_estimator_
print(dt.score(test_input, test_target))  
0.86
```






































































































